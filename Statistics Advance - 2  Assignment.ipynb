{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed2b61d-547e-4caa-b2d2-62782e50c6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question1: Define the z-statistic and explain its relationship to the standard normal distribution. How is thez-statistic used in hypothesis testing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3d43cb-d967-4feb-b5b6-d4e46baaf21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-Statistics and Its Relationship to the Standard Normal Distribution\n",
    "\n",
    "    #Z-statistics is a statistical measure that indicates how many standard deviations a data point (or sample mean) is from the population mean. It is widely used in hypothesis testing to determine whether to reject the null hypothesis.\n",
    "\n",
    "#Definition of Z-Statistics\n",
    "    #The formula for calculating Z-statistics is :\n",
    "       # Z = \\frac{X - \\mu}{\\sigma}\n",
    "    #: Individual data point or sample mean\n",
    "\n",
    "    #: Population mean\n",
    "\n",
    "    #: Population standard deviation\n",
    "\n",
    "# For sample means, the formula is adjusted as follows:\n",
    "    # Z = \\frac{\\bar{X} - \\mu}{\\frac{\\sigma}{\\sqrt{n}}}\n",
    "        #: Sample mean\n",
    "        #: Sample size\n",
    "\n",
    "\n",
    "# Relationship to the Standard Normal Distribution\n",
    "\n",
    "#1. Standard Normal Distribution: The Z-statistic follows the standard normal distribution, which has a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "#2. Critical Values: In hypothesis testing, the Z-statistic is compared to critical values from the standard normal distribution to determine statistical significance. For example, if the Z-value exceeds the critical value (like 1.96 for a two-tailed test at the 0.05 significance level), the null hypothesis is rejected.\n",
    "\n",
    "#3. Probability: The standard normal distribution enables the calculation of the probability of observing a Z-statistic as extreme as, or more extreme than, the calculated value under the null hypothesis.\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "    #In summary, Z-statistics standardizes data points concerning the population mean and standard deviation, which simplifies comparisons during hypothesis testing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abc438b-58c9-4ddb-939a-7cec1fca2242",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question2 : What is a p-value, and how is it used in hypothesis testing? What does it mean if the p-value isvery small (e.g., 0.01)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f06c7eb-a190-4719-8eb9-dfef49ccccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  A p-value is a statistical measure that indicates the probability of obtaining test results at least as extreme as the observed results, assuming the null hypothesis is true.\n",
    "   \n",
    "\n",
    "#Usage in Hypothesis Testing:\n",
    "\n",
    "#1. Formulation: In hypothesis testing, the null hypothesis () states there is no effect, while the alternative hypothesis () indicates there is an effect.\n",
    "\n",
    "#2. Calculation: After collecting data, a statistical test is performed to calculate the p-value.\n",
    "\n",
    "#3. Decision Making:\n",
    "\n",
    "#If p-value ≤ α (commonly 0.05): Reject the null hypothesis, indicating statistically significant results.\n",
    "\n",
    "#If p-value > α: Fail to reject the null hypothesis, suggesting results are not statistically significant.\n",
    "\n",
    "\n",
    "#Meaning of a Very Small P-Value (e.g., 0.01)\n",
    "\n",
    "#A very small p-value, such as 0.01, indicates strong evidence against the null hypothesis. This means there is only a 1% chance of observing the results if the null hypothesis were true, leading researchers to reject  and conclude that the results are statistically significant.\n",
    "\n",
    "##Conclusion\n",
    "\n",
    "    #In summary, the p-value helps assess the strength of evidence against the null hypothesis, with a very small p-value suggesting significant findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ee4f2f-afa2-4f88-bb43-2138b065e80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question3: Compare and contrast the binomial and Bernoulli distributions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1266759e-df2c-4384-b2b8-1e6280a0e4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare and Contrast the Binomial and Bernoulli Distributions\n",
    "\n",
    "#1. Definition:\n",
    "\n",
    "#Bernoulli Distribution: This distribution describes a single trial that has two possible outcomes: success (1) or failure (0). It represents a binary outcome from a single experiment, such as flipping a coin once.\n",
    "\n",
    "#Binomial Distribution: This distribution represents the number of successes in a fixed number of independent Bernoulli trials. It is concerned with the outcomes over multiple trials, such as flipping a coin multiple times and counting the number of heads.\n",
    "\n",
    "\n",
    "#2. Number of Trials:\n",
    "\n",
    "#Bernoulli: Involves only one trial (n = 1).\n",
    "\n",
    "#Binomial: Involves multiple trials (n > 1).\n",
    "\n",
    "\n",
    "#3. Parameters:\n",
    "\n",
    "#Bernoulli: Defined by one parameter, p , which is the probability of success in the trial.\n",
    "\n",
    "#Binomial: Defined by two parameters: n (the number of trials) and p (the probability of success in each trial).\n",
    "\n",
    "\n",
    "#4. Probability Mass Function (PMF):\n",
    "\n",
    "#Bernoulli:\n",
    "\n",
    "#The probability of success is given by .\n",
    "    #P(X = 1) = p\n",
    "\n",
    "#The probability of failure is given by .\n",
    "    #P (X = 0 ) = 1 - p\n",
    "\n",
    "#Binomial:\n",
    "#The probability of getting exactly  successes in  trials is given by:\n",
    "\n",
    "    # Formula: P(X = k) = (n choose k) * p^k * (1 - p)^(n - k), where \"n choose k\" is represented as:\n",
    "        #P(X = k) = \\binom{n}{k} p^k (1 - p)^{n-k}\n",
    "\n",
    "\n",
    "#5. Mean and Variance:\n",
    "\n",
    "#Bernoulli:\n",
    "\n",
    "    #Mean = p\n",
    "\n",
    "    #Variance = p(1 - p)\n",
    "\n",
    "\n",
    "#Binomial:\n",
    "\n",
    "    #Mean = n.p \n",
    "\n",
    "    #Variance = n.p (1 - p)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#6. Examples:\n",
    "\n",
    "#Bernoulli: An example is tossing a coin once, where heads could represent success and tails represent failure.\n",
    "\n",
    "#Binomial: An example is tossing a coin 10 times and counting how many times heads (success) appears.\n",
    "\n",
    "\n",
    "##Summary\n",
    "\n",
    "    #In summary, the Bernoulli Distribution is a special case of the Binomial Distribution that deals with a single trial, while the Binomial Distribution is used for multiple trials, counting the number of successes across those trials. Both distributions are crucial in statistics for modeling experiments with binary outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeb1c0e-239f-4df6-bc61-f66aa9c5d57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 4: Under what conditions is the binomial distribution used, and how does it relate to the Bernoullidistribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b9155c-0335-400a-8b56-e49a0d612c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditions for Using the Binomial Distribution\n",
    "\n",
    "#The Binomial Distribution is used under the following conditions:\n",
    "\n",
    "#1. Fixed Number of Trials: The experiment must consist of a fixed number of trials, denoted as .\n",
    "\n",
    "\n",
    "#2. Two Possible Outcomes: Each trial must result in one of two outcomes: success (often coded as 1) or failure (coded as 0).\n",
    "\n",
    "\n",
    "#3. Constant Probability: The probability of success  must remain constant across all trials.\n",
    "\n",
    "\n",
    "#4. Independence: The trials must be independent, meaning the outcome of one trial does not affect the outcome of another.\n",
    "\n",
    "\n",
    "#Relation to the Bernoulli Distribution\n",
    "\n",
    "    #The Binomial Distribution is essentially an extension of the Bernoulli Distribution. Here’s how they relate:\n",
    "\n",
    "    #The Bernoulli Distribution describes the probability of success in a single trial (n = 1), defined by one parameter , the probability of success.\n",
    "\n",
    "    #The Binomial Distribution models the total number of successes in  independent Bernoulli trials. It uses two parameters:  (the number of trials) and  (the probability of success in each trial).\n",
    "\n",
    "\n",
    "##In summary, the Binomial Distribution can be seen as a collection of multiple Bernoulli trials, making it suitable for analyzing scenarios where there are several independent trials with binary outcomes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7262617-2676-4250-abab-df68bcab4599",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Question5: What are the key properties of the Poisson distribution, and when is it appropriate to use thisdistribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300f3d73-5b60-4422-a794-5d828c4797d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key Properties of the Poisson Distribution\n",
    "\n",
    "#1. Definition: The Poisson distribution models the number of events occurring in a fixed interval of time or space with a known average rate and independent occurrences.\n",
    "\n",
    "\n",
    "#2. Parameter: It is defined by a single parameter  λ (lambda), which represents the average number of events.\n",
    "\n",
    "\n",
    "#3. Probability Mass Function (PMF):\n",
    "\n",
    "#P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\n",
    "\n",
    "#4. Mean and Variance: Both the mean and variance of a Poisson distribution are equal to  λ.\n",
    "\n",
    "#5. Independence: Events occur independently within non-overlapping intervals.\n",
    "\n",
    "\n",
    "\n",
    "# When to Use the Poisson Distribution\n",
    "\n",
    "#Rare Events: Suitable for modeling rare events over a fixed interval, like the number of accidents at an intersection in a month.\n",
    "\n",
    "#Constant Rate: When the average rate of occurrence ( λ) is known.\n",
    "\n",
    "#Discrete Count: Used for counting discrete events in continuous time or space.\n",
    "\n",
    "#Short Intervals: Effective for small time intervals where the likelihood of multiple events is low.\n",
    "\n",
    "\n",
    "##Summary\n",
    "\n",
    "    #The Poisson distribution is characterized by its single parameter  λ and is used to model the number of rare, independent events occurring at a constant average rate within a specified time or space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db50264-5e11-4b38-bf3e-5e77c85b97a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question6: Define the terms \"probability distribution\" and \"probability density function\" (PDF). How does aPDF differ from a probability mass function (PMF)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc56ee4e-6d22-41b7-9c93-401889e15ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probability Distribution\n",
    "\n",
    "#A probability distribution is a mathematical function that describes the likelihood of different outcomes in a random experiment. It assigns probabilities to each possible value of a random variable. Probability distributions can be discrete or continuous.\n",
    "\n",
    "#Probability Density Function (PDF)\n",
    "\n",
    "#A probability density function (PDF) is used in continuous probability distributions to specify the probability of a random variable falling within a particular range of values, rather than taking on a specific value. The area under the curve of the PDF over a specified interval gives the probability of the random variable falling within that interval. The total area under the PDF curve equals 1.\n",
    "\n",
    "\n",
    "#Difference Between PDF and PMF\n",
    "\n",
    "#Type of Distribution:\n",
    "\n",
    "    #PDF: Used for continuous random variables.\n",
    "\n",
    "    #PMF: Used for discrete random variables.\n",
    "\n",
    "\n",
    "#Probability Representation:\n",
    "\n",
    "    #PDF: Represents probabilities as areas under the curve; the probability of a specific value is 0.\n",
    "\n",
    "    #PMF: Represents probabilities for specific outcomes, where the probability of each discrete value is greater than 0.\n",
    "\n",
    "\n",
    "#Calculation:\n",
    "\n",
    "    #PDF: Probability of an interval a < X < b is calculated as:\n",
    "\n",
    "#P(a < X < b) = \\int_a^b f(x) \\, dx\n",
    "\n",
    "#P(X = k) = p(k)\n",
    "\n",
    "##Summary\n",
    "\n",
    "    #In summary, a probability distribution encompasses the behavior of random variables, while a PDF provides the likelihood for continuous variables. PMFs do the same for discrete variables, with key differences in how probabilities are represented and calculated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9982773e-5dd9-4fd3-9fe3-2981adf38985",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question7: Explain the Central Limit Theorem (CLT) with example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f390cad1-d03a-4688-a22a-602d2e630660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Central Limit Theorem (CLT)\n",
    "\n",
    "# The CLT stats that if you have a population with a mean μ and stander deviation σ and take suffjiciently large number of random sample from the population with replacement ( member can be repeated in samples ) , than the distribution of sample means will be approximately normally distributed.\n",
    "\n",
    "\n",
    "#Key Points:\n",
    "\n",
    "#Mean: The mean of the sampling distribution is equal to the population mean (μ).\n",
    "\n",
    "#Variance: The variance of the sampling distribution is equal to the population variance (σ2) divided by the sample size n (σ2/n).\n",
    "\n",
    "\n",
    "#Example\n",
    "\n",
    "    #Scenario: Consider a population of students' test scores that are skewed.\n",
    "\n",
    "#1. Population Mean ( μ ): 70\n",
    "\n",
    "\n",
    "#2. Population Standard Deviation (σ): 10\n",
    "\n",
    "    #If we take random samples of size n = 30 and calculate their means:\n",
    "\n",
    "#The distribution of these sample means will approximate a normal distribution.\n",
    "\n",
    "#The mean of this distribution will be approximately 70, and the standard deviation (standard error) will be σ /  √n = 10 /  √30 ~~ 1.83.\n",
    "\n",
    "\n",
    "##Summary\n",
    "\n",
    "    #The Central Limit Theorem allows statisticians to use the normal distribution to make inferences about population parameters, even if the original distribution is unknown, as long as the sample size is sufficiently large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b38be7-1274-4bd6-829b-1287c7ce5dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question8: Compare z-scores and t-scores. When should you use a z-score, and when should a t-score be applied instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af34fcbb-57aa-48b3-adfd-7b08ea33a513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-scores vs. T-scores\n",
    "\n",
    "#Z-score:\n",
    "\n",
    "    #Definition: Measures how many standard deviations an element is from the mean of a distribution.\n",
    "\n",
    "#Formula:\n",
    "\n",
    "#Z = x - μ / σ\n",
    "\n",
    "#Use Case: Used when the population variance is known or when the sample size is large (n >= 30).\n",
    "\n",
    "#Distribution: Assumes normal distribution.\n",
    "\n",
    "\n",
    "#T-score:\n",
    "\n",
    "    #Definition: Similar to a z-score but accounts for sample size and is used when estimating the population mean.\n",
    "\n",
    "#Formula:\n",
    " #T = X - x̄ / s √n\n",
    "\n",
    "#Use Case: Used when the population variance is unknown and the sample size is small (n  < 30).\n",
    "\n",
    "#Distribution: Follows a t-distribution, which is wider and has heavier tails than the normal distribution.\n",
    "\n",
    "\n",
    "##Summary\n",
    "\n",
    "    #Use z-scores for large samples or known population parameters.\n",
    "\n",
    "    #Use t-scores for small samples or unknown population parameters.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
